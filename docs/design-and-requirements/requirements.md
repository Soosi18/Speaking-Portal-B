# **Project Requirements**

## **Project Description**
- The Speaking Portal project acts as an add-on to Kukarella’s existing web platform to pair with the company’s text-to-speech(TTS) software solution. It involves the generation of a 2D-animated video with the help of user-input text, the speech file generated by Kukarella's TTS, and an avatar selected from a list of available models. It also provides the user an video embed code/link and the option to download the generated video file.


## **Target User Groups**

- Casual Users/Enthusiasts: Users who are interested in the animated video generation feature and want to try it out.

- Professional Users/Companies: Users working in various fields such as education and marketing, who wish to integrate the animated video into their lectures, meetings, presentations, etc. in order to enhance their audience's experience.

- Kukarella Developer Team: Responsible for integrating the software with their existing application and making any desired changes

## **Software Requirements**

### **Functional Requirements**

- Receive user-input text through existing Kukarella TTS implementation via API request.

- Receive 2D avatar image chosen by the user from a list of options via API request.

- Receive speech file generated by Kukarella TTS implementation via API request.

- Create animated 2D video based on user-selected avatar, text and speech file.

- Store animated video in database.

- Provide an embed link for the generated video.

- Allow user to download the generated video.

### **Non-Functional Requirements**

- **Performance** – Low buffer times, fast generation of animated video.
- **Code Quality** – Code must be professionally formatted, linted and maintained.
- **Robustness** - Ensuring that there are no failures through testing.
- **Efficiency** - Maximum utilization of resources for fastest response times.
- **Accuracy** - Accurate/realistic lip-syncing of animated video avatar to TTS audio.

### **User Requirements**

Through the Kukarella App:

- Users are able to enter the text that they want to convert either through typing or by uploading a text file.

- Users select a 2D avatar (from a list of available avatars) that they want the animation to be created with.

- Users can view a list containing all available languages for the audio and select their desired language.

- Users can view a list containing all available voices for the selected langauge audio.

- Users can play a test/sample for each voice and make a selection based on their preferences.

- Users can request the video to be generated by clicking on a confirmation button.

- Users can view the generated video.

- Users can copy the embed code/link for the generated video.

- Users can download the generated video.

### **Constraints/Risks**

- Inexperience with 2D animation - lack of knowledge with regards to animation process or libraries or frameworks that help with animation. This may lead to animation quality not meeting client's standards.

- No support for custom avatars - Animation capabilities limited to existing avatars provided by client.

- Project time constraints - Limited time to complete the project, team members need to focus on other courses every week.

### **Choice of Tech Stack**

### **Data Flow Diagram (Level 0)**

### **Data Flow Diagram (Level 1)**

### **Milestones**

Milestone 1 (Requirements Report) - Functional, non-functional and user requirements; Data-flow diagrams (level 0 and 1); Choice of tech stack; Testing strategies (Due Oct. 21)

Milestone 2 (Peer Testing I) - Program receives selected avatar, text and speech file input through Kukarella API; Program generates phoneme sequence and resulting viseme sequence; Program aligns viseme sequence with audio file; Program combines viseme sequence to generate video; Program allows for download of generated video; Program has simple interface/GUI that allows for peer testing (Due Nov. 25)

Milestone 3 (Peer Testing II) - Incorporate feedback from Peer Testing I; API endpoints to access program's features; Support for custom/user-uploaded avatar animation if possible (Due Mar. 3)

Milestone 4 (Final Product) - Incorporate feedback from Peer Testing II; Implementation of bonus features such as subtitles, additional facial animation, etc.; Finish documentation (Due Apr. 21)

### **Testing Strategies**

- Unit Testing features using PyTest.

- Regression Testing with the help of GitHub Actions workflows: Running all tests after a Pull Request to the main branch is created to ensure all previously written tests are passed even with the new code being implemented.

- Integration Testing: Ensuring all components of the software work together by making calls to the API and comparing results with expected outputs.

- Usability Testing: Involves target user groups' feedback on product prototypes to ensure software is working as intended and to gather their impressions on features such as satisfaction with animation quality, video generation speed, etc.
### **Team Questions**

1. Do professional users require a login?  
A: A professional account on Kukarella will be required to use the video generation feature.
  
2. Is the generated video going to go to a template page for viewing then deleted a certain amount of time after the generation of the page?
  A: The video is going to be stored in a database, but we are currently unsure of how long it will be stored for. We will clarify with the client in our future    meetings!
  
3. Will you need help from professional artists/animators in order to create the code for animations? If yes, how do you plan on contacting such people?
  A: We will require 2D assets previously made by Kukarella’s animators. Should the need arise, we will be requesting the animators to create additional assets such as   different mouth shapes for all the phonemes, etc.
  
4. What metrics will you use to check the accuracy of the syncing? Do you have a definition for “seamlessly flowing audio”?
  A: If phonemes have an 80% rate of being recognized successfully, this is within the margin of error for seamless audio. We will also make sure that the testers of     our application find the animation smooth and “in-sync” during the Usability Testing phase sometime during Term 2.
  
5. How do you plan on implementing the download function for users? Will you use a video hosting service?
  A: Generated videos will be stored in object storage on AWS or Google Compute, and we’ll expose a download URL from there. 

6. What practices will you be following in order to provide professionally formatted code?
  A: All of us use VSCode to write code, which has extremely good linters like Flake8, etc that will help us check for simple logical as well as stylistic errors..       Other than that, we will be following the practice of decorators and comments to explain the code we are writing. All code will need to be reviewed by at least 2       other team members before it is merged to the main branch of the GitHub repository. This will help ensure that the quality is acceptable by all members of the team.

7. Are you concerned with Python's relatively poor performance relative to other languages?
  A: Python has poor performance relative to Javascript only for web servers, for which we will use NodeJS. Python is better at processing video and various ML models.

8. How do you plan on testing components working together?
  A:
  
9. How do you plan to ‘maximize efficiency’ for fast response times?
  A: For the front-end, we will be using NextJS which has server-side rendering one of the best load times in the industry. Our web-server will be deployed using         Google Cloud functions which are almost infinitely scalable low latency endpoints. Our compute for video generation we will be using cloud compute with GPUs.

10. Are you concerned about the computing speed python provides (given its not exactly known for being performant)?
  A: Python has poor performance relative to Javascript only for web servers, for which we will use NodeJS. Python is better at processing video and various ML models.

11. What is the definition of "fast generation?" Why did you choose this timeframe?
  A: This is a poor choice of words. A better timeline would be time/data = gen time

12. Are you animating this yourself? The presentation made it seem like you were.
  A: We are going to get some assistance from our clients in terms of borrowing already existing 2D assets that they have on hand, but we will be animating by            ourselves.
