# API Docs

The API is built using Flask. The API is hosted on a local server. The API accepts a text file, an audio file, and a language parameter as an input. It then parses the files to make sure the files are safe or proper for further processing.

It has only one endpoint, which is the ```/generate``` endpoint. The endpoint accepts a ```PUT``` request with the following parameters:

1. ```text_file```: The text file that contains the text that used on Kukarella to convert to speech.

2. ```audio_file```: The audio file that was received from Kukarella on converion of the text file.

3. ```lang```: The language of the text file.
    
    We support the following languages:
    ```python
    SUPPORTED_LANGUAGES = ["english", "french", "japanese"]
    ```

## Flow of the API
Notes: 
- All functions that are used in app.py can be found in the ```src/api/functions``` directory.
- The input received from the server is saved in the ```server_files/jobs/inputs``` directory.
- The outputs and temp files generated during the process are saved in the ```server_files/jobs/outputs``` directory.

1. The API parses the received files to make sure they are safe and proper for further processing. It checks whether the files have been received or not, and whether the files are of the correct type or not. If the files are not safe, the API returns a ```400``` error. If the files are ready for processing it saves the files in their job directory which resides in the ```server_files/jobs/inputs``` directory.
The name of the directory is the job id which is ```uuidv4``` generated by the API. The text file and audio are renamed to the ```uuid``` and saved in the job directory.

2. The API then calls the ```mfa.align()``` method runs the montreal forced aligner on the text file and audio file. The output of the aligner is a ```json``` file that contains the alignment of the audio file with the text file. The ```json``` file is saved in the ```server_files/jobs/outputs``` directory with the same name as the job id.

3. There are language specific methods for japanese and french to get the mouths to align correctly.

4. The ```mfa.converter()``` method is used to convert the structure of the mfa output to a ```json``` structure that is digestible by the scheduler.

5. The ```scheduler.frame_schedule``` method is used to align the phones with corresponding mouth shapes. The scheduler uses the ```json``` file from the previous step to align the mouth shapes with the phones. 

6. The ```videoDrawer.runVideoDrawer()``` method draws the frames for the video according to the schedule generated by the scheduler. The frames are saved in the ```server_files/jobs/outputs/frames``` directory with the same name as the job id.

7. Lastly, the ```ffmpeg``` is used to stitch the frames together to create a video. The video is saved in the ```server_files/jobs/outputs``` directory with the same name ```generatedVideo.mp4```.

8. This video is sent back to the user as a response.

9. All files relevant to the job are deleted from the server.